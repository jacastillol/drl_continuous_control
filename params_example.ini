#  ***************************************************
#  ************* This is an example file *************
#  *                                                 *
#  *  Please DO NOT write on it                      *
#  *    1. copy this file                            *
#  *    2. save as 'params.ini'                      *
#  *                                                 *
#  ***************************************************
[DEFAULT]
# max. number of episode to train the agent
n_episodes:       200
# max. number of steps per episode
max_t:           1000
# save the last XXX returns of the agent
print_every:       10
# replay buffer size
SEED:               0
# replay buffer size
BUFFER_SIZE:      1e5
# minibatch size
BATCH_SIZE:       128
# how often to update the network
UPDATE_EVERY:       2
# discount factor
GAMMA:           0.99
# std noise over actions for exploration
SIGMA:           0.05
# for soft update or target parameters
TAU:             1e-3
# learning rate of the actor
LR_ACTOR:        1e-4
# learning rate of the critic
LR_CRITIC:       3e-4
# L2 weight decay
WEIGHT_DECAY:  0.0001
# number of neurons in actor first layer
FC_ACTOR:          32
# number of neurons in critic first layer
FC1_CRITIC:        32
# number of neurons in critic second layer
FC2_CRITIC:        16
